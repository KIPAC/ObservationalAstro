{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMD976sPmdTf"
   },
   "source": [
    "# Lab 0.2: Calibration, Stacking, and Pretty Pictures!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mpCtkJ3vmdTh"
   },
   "source": [
    "*Due: Wednesday, April 9 before observing. We will spend the first computer lab working on this notebook.*\n",
    "\n",
    "This lab walks through calibration and stacking of raw images from the telescope. By the end of this lab, you will be able to\n",
    " - perform image calibration using darks, flats, and biases\n",
    " - analyze the performance of the camera and telescope using these files\n",
    " - align and stack multiple exposures of the same object\n",
    " - combine images from individual filters to make a pretty color image\n",
    "\n",
    "Depending on your background, this lab may also be a crash course in scientific computing with Python, so start this one early! We recommend opening this notebook with Google Colab and making a copy in Google Drive so that you can (1) easily load data from the shared class folder, (2) avoid Python installation and environment headaches, and (3) easily collaborate with your team later in the quarter. If you would like to switch to a different workflow for the final project, we'll happily help you set that up.\n",
    "\n",
    "You should complete the key conceptual lines of code marked with `TODO:`, answer the **bolded questions**, and read the comments for the rest of the code to make sure you understand what's going on. When you're done, save the notebook as a PDF with cell outputs included and upload to Canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LhTMkYCQmdTi"
   },
   "outputs": [],
   "source": [
    "# If using Colab, mount your Google Drive to access data in the shared folder\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cncPRzTdmdTj"
   },
   "outputs": [],
   "source": [
    "# If using Colab, need to install the reproject package\n",
    "%pip install reproject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QhihmAZrmdTk"
   },
   "outputs": [],
   "source": [
    "# Import packages!\n",
    "\n",
    "# numpy is a core package for numerical computing in Python, mostly it does fast array operations\n",
    "import numpy as np\n",
    "\n",
    "# matplotlib is a common plotting library (plotly is another good one)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# astropy is useful for reading FITS files, doing coordinate transformations, converting units, and much more\n",
    "import astropy\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS # World Coordinate System\n",
    "\n",
    "# reproject allows us to reproject images onto the same coordinates before stacking\n",
    "from reproject import reproject_interp\n",
    "\n",
    "# glob and os are useful for navigating your file system\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# miscellaneous\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjAVW5K-mdTl"
   },
   "source": [
    "## Calibrating Astronomical Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htRM2f3ImdTm"
   },
   "source": [
    "Before we jump into the code, here is a quick primer on calibrations for any charge coupled device (or CCD) camera and why they are necessary. The text has been lifted heavily from [Howell (2006, chapter 4)](http://adsabs.harvard.edu/abs/2006hca..book.....H).\n",
    "\n",
    "### Bias\n",
    "Every camera offsets the zero level so that the A/D converter never outputs a negative number. This offset is different for every camera and every camera setting (for those cameras with changeable settings). This \"bias\" value is not necessarily constant for every pixel and must be measured so that it can be subtracted from the raw science frame.\n",
    "\n",
    "The bias image has an exposure time of zero seconds. The shutter remains closed and the CCD is simply read out. The purpose of a bias or zero frame is to allow the user to determine the underlying noise level within each data frame. The bias value in a CCD image is usually a low spatial frequency variation throughout the array, caused by the CCD on-chip amplifiers. This variation should remain constant with time. The rms value of the bias level is the CCD read noise. A bias frame contains both the DC offset level (overscan) and the variations on that level. The nature of the bias variations for a given CCD are usually column-wise variations, but may also have small row-wise components as well. Thus, a 2-D, pixel-by-pixel subtraction is often required. A single bias frame will not sample these variations well in a statistical fashion, so an average bias image of 10 or more single bias frames is recommended.\n",
    "\n",
    "### Dark\n",
    "Photons are emitted from every body with a non-zero temperature (on the Kelvin scale). Therefore everything emits light, even your camera. These thermal photons can cause a signal in a sensitive CCD camera and therefore the rate at which this occurs needs to be accounted for in a fully calibrated image.\n",
    "\n",
    "CCD dark frames are images taken with the shutter closed but for some time period, usually equal to that of your target frames. That is, if one is planning to dark correct a 45 second exposure, a 45 second dark frame would typically be obtained. Longer dark frames can often be avoided using the assumption that the dark current increases linearly with time and a simple scaling can be applied. However, this is not always true. Dark frames are a method by which the thermal noise (dark current) in a CCD can be measured. They also can give you information about bad or \"hot\" pixels that exist as well as provide an estimate of the rate of cosmic ray strikes at your observing site. Observatory class CCD cameras are usually cooled with liquid nitrogen to temperatures at which the dark current is essentially zero. Many of these systems therefore do not require the use of dark exposure CCD frames in the calibration process. Thermoelectrically cooled systems are typically not cooled to low enough temperatures such that one may ignore the dark current, but they are getting better. In addition, these less expensive models often have poor temperature stability allowing the dark current to wander a bit with time. Multiple darks averaged together are the best way to produce the final dark calibration frame. Note that the bias is also present in dark frames. To get an accurate measure of the dark current, the bias must be subtracted.\n",
    "\n",
    "### Flat\n",
    "Not every pixel in a CCD camera responds to the sky in the exact same way. There are many reasons for this. For one, not every pixel is created equally, so there may be some intrinsic sensitivity difference from pixel to pixel. However, the CCD may be obscured slightly by the optics of the telescope, or by dust on the camera or filters. Therefore this pixel-to-pixel variation must also be accounted for.\n",
    "\n",
    "Flat field exposures are used to correct for pixel-to-pixel variations in the CCD response as well as any nonuniform illumination of the detector itself. Flat fields expose the CCD to light from either a dome screen, the twilight sky, the nighttime sky, or a projector lamp in an attempt to provide a high signal-to-noise ratio (SNR) uniformly illuminated calibration image. For narrow-band imaging, flats are very helpful in removing fringing, which may occur in object frames. Flat field calibration frames are needed for each color, wavelength region, or different instrumental setup used in which object frames are to be taken. A good flat should remain constant to about 1%, with 2% or larger changes being indicators of a possible problem. As with the other calibration frames, at least 5 or more flat fields should be taken and averaged to produce the final flat used for image calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u2ujglTmmdTo"
   },
   "outputs": [],
   "source": [
    "# Specify data directory, and which object we want from which date\n",
    "data_dir = '/content/drive/MyDrive/PHYSICS100_S2025/data' # add a shortcut to PHYSICS100_S2025 in your Google Drive for easy access\n",
    "object_name = 'm51' # TODO: change this to the object you observed, although we recommend completing the notebook with the M51 example first\n",
    "date_string = '2024_04_28'\n",
    "telescope_name = '0.7m'\n",
    "\n",
    "# Gather all the filenames for the object and dates\n",
    "filenames = {k: glob.glob(os.path.join(data_dir, 'calibration', telescope_name, date_string, f'{k}*.fit'))for k in ['flat', 'dark', 'bias']} # calibration exposures\n",
    "filenames['light'] = glob.glob(os.path.join(data_dir, object_name, telescope_name, date_string, '*.fit')) # raw science exposures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8frkHy3TmdTo"
   },
   "outputs": [],
   "source": [
    "# Sort the data and headers into dictionaries (defaultdicts are like dictionaries, but they create new keys automatically)\n",
    "data = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "headers = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "\n",
    "# For each type of exposure, load all the files and append them to the appropriate lists\n",
    "for k in filenames.keys():\n",
    "    for fn in filenames[k]:\n",
    "        with fits.open(fn) as hdul:\n",
    "            filter = hdul[0].header['FILTER'] if 'FILTER' in hdul[0].header else None # get filter from header\n",
    "            exp_time = hdul[0].header['EXPTIME'] # get exposure time from header\n",
    "            data[k][filter][exp_time].append(hdul[0].data) # append data to the appropriate list\n",
    "            headers[k][filter][exp_time].append(hdul[0].header) # append header to the appropriate list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FgMO13NRmdTq"
   },
   "outputs": [],
   "source": [
    "# This is how we access the first flat data for filter R and exposure time 0.2 seconds\n",
    "data['flat']['R'][0.2][0]\n",
    "\n",
    "# This is how we access the second light header for filter V and exposure time 30 seconds\n",
    "headers['light']['V'][30.0][1]\n",
    "\n",
    "# This is how we see which exposure times are in the dictionary for darks (`None` is because the dark has no filter)\n",
    "data['dark'][None].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXiRlv7QmdTr"
   },
   "source": [
    "**Question: Why do we need 0.1 s, 0.2 s, and 30 s darks in the example M51 observations? Why do biases not have a filter or exposure time?**\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nz-DwgcemdTr"
   },
   "outputs": [],
   "source": [
    "# Compute average bias\n",
    "bias_frames = np.array(data['bias'][None][0.0]) # Bias has no filter and 0.0s exposure time\n",
    "avg_bias = # TODO: Compute the average bias frame (hint: use np.mean with the axis argument)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rex3vV_ymdTs"
   },
   "source": [
    "**Question: What is the shape of the `bias_frames` array? What does each dimension represent?** (Hint: use `.shape`)\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W2s5R6mLmdTw"
   },
   "outputs": [],
   "source": [
    "# Look at the average bias\n",
    "plt.imshow(avg_bias, cmap='gray', vmin=, vmax=) # TODO: Set vmin and vmax so that you can see the structure in the image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAl9BgEBmdTx"
   },
   "source": [
    "**Question: What is the typical value of the bias? Why does it look noisy? Is there any structure to the noise?**\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SkO45chdmdTy"
   },
   "outputs": [],
   "source": [
    "# Compute average dark for each exposure time (note: if some exposure times were missing, you would have to scale an existing dark appropriately)\n",
    "avg_darks = {}\n",
    "for time, darks in data['dark'][None].items(): # Dark has no filter\n",
    "    avg_darks[time] = # TODO: compute the average dark and subtract the average bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qD4AeYjMmdTy"
   },
   "outputs": [],
   "source": [
    "# Make a histogram of the dark current at different exposure times\n",
    "hist_range = # TODO: Set the range of the histogram to ignore the outliers\n",
    "plt.hist(avg_darks[0.1].flatten(), range=hist_range, bins=20, histtype='step', label='0.1 s')\n",
    "plt.hist(avg_darks[0.2].flatten(), range=hist_range, bins=20, histtype='step', label='0.2 s')\n",
    "plt.hist(avg_darks[30].flatten(), range=hist_range, bins=20, histtype='step', label='30 s')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QN21_u3tmdTy"
   },
   "source": [
    "**Question: What is the typical value of the dark current and do you see any difference between exposure times? What does this tell you? What do you think the outliers are?**\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jaUJFV39mdTy"
   },
   "outputs": [],
   "source": [
    "# Compute median flat for each filter\n",
    "median_flats = {}\n",
    "\n",
    "for filter in data['flat'].keys():\n",
    "    all_normed_flats = []\n",
    "    for time, flats in data['flat'][filter].items():\n",
    "        corrected_flats = # TODO: subtract average bias and corresponding dark from each flat\n",
    "        normed_flats = # TODO: normalize flats so that they have a median value of 1.0 (hint: use axis=(1,2) and keepdims=True)\n",
    "        all_normed_flats.append(normed_flats)\n",
    "    all_normed_flats = np.concatenate(all_normed_flats, axis=0)\n",
    "    median_flats[filter] = # TODO: compute the median flat for each filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHUtyqXgmdTy"
   },
   "source": [
    "**Question: Why do we use the median for the flats but average for darks and biases?**\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OVLf0azFmdTz"
   },
   "outputs": [],
   "source": [
    "# TODO: Plot the median flat for each filter, like we did for the bias\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(15,5))\n",
    "for i, (filter, flat) in enumerate(median_flats.items()):\n",
    "    axes[i].imshow(flat, cmap='gray')\n",
    "    axes[i].set_title(filter)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtvTBWMHmdTz"
   },
   "source": [
    "**Question: What do you see in the flats? Explain what causes this and why it has that shape.**\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6hQUAaqWmdTz"
   },
   "outputs": [],
   "source": [
    "# Calibrate all science images\n",
    "calibrated_data = defaultdict(lambda: defaultdict())\n",
    "\n",
    "for filter, dict in data['light'].items():\n",
    "    for time, lights in dict.items():\n",
    "        dark = # TODO: get the right dark for this exposure time\n",
    "        flat = # TODO: get the right flat for this filter\n",
    "        calibrated_lights = # TODO: correct for bias, dark, and flat (hint: two are subtracted, one is divided)\n",
    "        calibrated_data[filter][time] = calibrated_lights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2emW_h9imdTz"
   },
   "source": [
    "**Question: In the cell above, which are subtracted, which are divided, and why?**\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Pvs5b02mdT0"
   },
   "source": [
    "## Stacking Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t--vBNdsmdT0"
   },
   "source": [
    "Now we will step you through the basic procedure to stack images (or \"coadd\") to achieve a higher signal-to-noise ratio (SNR). We will use the calibrated images we just created above. Individually, it may be difficult to pick out the faint details from a single image, but by stacking the images we should obtain a \"deeper\" image that shows more subtle detail including fainter objects in the field.\n",
    "\n",
    "Unfortunately, image stacking can often be a more difficult process than it initially seems. Objects on the night sky are moving, and while the telescopes make a concerted effort to track these movements, the positions of your objects may not be constant across many frames.\n",
    "\n",
    "What we are going to do is align every image with a reference image. What should we choose as our reference image? There is really no right answer here, but you can imagine that choosing the middle image might make a lot of sense. For instance, if the tracking drifted over the course of obtaining these images, the middle image might be the easiest to align with since it might minimize the amount of shifting for the set of images.\n",
    "\n",
    "Note that images from the 24\" telescope need to be \"solved\" to add the necessary RA and dec information to their FITS headers. This may be a good idea for images from the 0.7 m as well. If we don't have time to do this at the telescope, you may need to do this yourself with ASTAP (see the addendum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MmLAIGoDmdT0"
   },
   "outputs": [],
   "source": [
    "# Coadd the calibrated science images\n",
    "coadded_science = {}\n",
    "reference_header = headers['light']['V'][30.0][10] # choose one header to serve as the reference to project other images onto\n",
    "warnings.filterwarnings('ignore', category=astropy.wcs.FITSFixedWarning) # ignore when astropy fixes a FITS file\n",
    "\n",
    "for filter in calibrated_data.keys():\n",
    "\n",
    "    # Create arrays to hold the stacked data and exposure time per pixel\n",
    "    stacked_image = np.zeros(calibrated_data[filter][30.0][0].shape)\n",
    "    stacked_footprint = np.zeros(calibrated_data[filter][30.0][0].shape)\n",
    "    total_exposure = 0\n",
    "\n",
    "    for time, images in calibrated_data[filter].items():\n",
    "        for i, image in enumerate(tqdm(images, desc=f'Filter {filter} {time} s')): # use tqdm progress bar with custom description\n",
    "\n",
    "            # TODO: reproject the science image into the same coordinates as the reference image (hint: use reproject_interp, look up the documentation)\n",
    "            =\n",
    "\n",
    "            # TODO: update the stacked arrays\n",
    "            stacked_image +=\n",
    "            stacked_footprint +=\n",
    "            total_exposure +=\n",
    "\n",
    "    # TODO: throw away parts of image not covered by all exposures, by setting to np.nan (\"not a number\", often used for invalid values)\n",
    "    # Hint: the code will look something like a[b!=c] = np.nan, this means set all elements of a where b is not equal to c to np.nan\n",
    "    = np.nan\n",
    "\n",
    "    # Update header with new exposure time\n",
    "    new_header = reference_header.copy()\n",
    "    new_header['EXPTIME'] = total_exposure\n",
    "    new_header['EXPOSURE'] = total_exposure\n",
    "    new_header['FILTER'] = filter\n",
    "\n",
    "    # Final stacked HDU\n",
    "    coadded_science[filter] = fits.PrimaryHDU(stacked_image, new_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hhSQJfjmdT0"
   },
   "source": [
    "**Question: Why is it taking so long? What's so complicated about shifting an image?**\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9sxi0Ey6mdT0"
   },
   "outputs": [],
   "source": [
    "# Plot coadded science images, use log scale to see fainter features\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(15,5))\n",
    "for i, (filter, hdu) in enumerate(coadded_science.items()):\n",
    "    axes[i].imshow(hdu.data, cmap='gray', vmin=np.nanpercentile(hdu.data, 0.1), vmax=np.nanpercentile(hdu.data, 99.9), norm='log')\n",
    "    axes[i].set_title(filter)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8u8mvzZ2mdT1"
   },
   "outputs": [],
   "source": [
    "# If you want, the code below will save the coadded images to wherever you specify\n",
    "# for filter in coadded_science.keys():\n",
    "#     hdul = fits.HDUList([coadded_science[filter]])\n",
    "#     hdul.writeto(os.path.join('<INSERT FOLDER PATH HERE>', 'coadd_{}_{}_{:.0f}s_{}.fit'.format(object_name, filter, coadded_science[filter].header['EXPTIME'], date_string)), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8thdep8mdT2"
   },
   "source": [
    "## Making Color Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkP4uqDBmdT2"
   },
   "source": [
    "As you may have noticed, the images that we have been working with have all been grayscale. So how do you make a color image? It is a lot more intensive that snapping a shot with your phone, but it also will likely give you much more insight into everything that your phone does.\n",
    "\n",
    "Matplotlib has the ability to show color images if you specify the levels of Red, Green, and Blue in each pixel (i.e. an array specifying specific colors in an RGB image). For Python to recognize your input as an image, these values must be either decimals in [0,1] or integers in [0,255]. Because the exposures you took of your astronomical object differ in exposure in different bands, it is typical to rescale each color image to these bounds, along with \"clipping\" the data to account for outliers. To make fainter details more apparent, we can also take the square root or other power of the clipped data. Feel free to try your own limits and scaling fuctions to make the best image possible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jC0PZkigmdT2"
   },
   "outputs": [],
   "source": [
    "# Create composite image\n",
    "composite = np.stack([coadded_science[f].data for f in ['R','V','B']], axis=-1)\n",
    "clip_min = np.nanpercentile(composite, 80, axis=(0,1)) # minimum at 80th percentile\n",
    "clip_max = # TODO: Set the maximum at a percentile that looks good\n",
    "composite = np.clip(composite, clip_min, clip_max)\n",
    "composite = (composite - clip_min)/(clip_max - clip_min)\n",
    "composite = # TODO: Take the square root or another fractional power to make the image look better\n",
    "\n",
    "# Plot\n",
    "plt.imshow(composite)\n",
    "plt.axis('off')\n",
    "plt.gcf().tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbfmoQy6mdT2"
   },
   "source": [
    "**Question: What do you notice in your final composite image? No right or wrong answer here and questions are as good as answers!**\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jEnz4eO-mdT3"
   },
   "source": [
    "## Addendum: Plate Solve with ASTAP (no work required here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bhu7wabMmdT3"
   },
   "source": [
    "One funny quirk of our 24\" telescope: the computer for the mount (which tracks and calculates astrometry)\n",
    "and the camera (which you instruct to take your exposures/calibration files) do not communicate with each\n",
    "other. This means that the FITS file header for your astronomical images do not contain RA and dec\n",
    "information that is extremely useful when aligning and stacking images together. Even for the 0.7 m telescope, the RA and dec information may not be accurate enough for stacking. While it is possible to\n",
    "stack images by calculating statistics of reference stars and aligning pixels, we opt for the method of adding\n",
    "astrometric information to the FITS headers before alignment. We can do this via the Astronomy Stacking\n",
    "Program (ASTAP). Using this [link](https://www.hnsky.org/astap.htm), you can download the software (available for Windows, Mac, and Linux) as well as a star catalogue (D80 recommended if you have the space; ∼ 1GB) to compare to a reference image.\n",
    "\n",
    "For each batch of images input to ASTAP, you can select a reference image to use for alignment. There are\n",
    "multiple methods for solving, though we recommend you select Star or Astrometric alignment. This will\n",
    "use the downloadable stellar catalogue to match with reference stars in your image, calculating an RA and\n",
    "dec for each pixel in your image. The FITS header will be overwritten, and images can be easily combined\n",
    "with traditional FITS handlers in Python. ASTAP also has built-in stacking\n",
    "and calibration, but we will be doing this in Python to maintain flexibility.\n",
    "You can find a detailed index of ASTAP functions via their [helpful guide](https://www.hnsky.org/astap.htm#alignment_menu).\n",
    "\n",
    "We may have time to do the plate solving at the telescope so that each group does not need to do this individually on their own computers. If not, TAs will be available to answer questions on how to use the software during the Computer Labs. Either way, you'll need to do this yourself for the final project so it's a good idea to start learning."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "obsastro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}